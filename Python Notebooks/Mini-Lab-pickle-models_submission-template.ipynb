{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Lab -- Pickle Models\n",
    "\n",
    "This mini-lab is a follow-up to some in-class activities we've done.\n",
    "It intentionally doesn't remind you explicitly how to do stuff, because\n",
    "part of the activity is to learn how to do these things on your own!\n",
    "\n",
    "\n",
    "## Hints\n",
    "\n",
    "Read this: https://scikit-learn.org/stable/modules/model_persistence.html\n",
    "\n",
    "\n",
    "## Deliverable\n",
    "\n",
    "Complete the following functions, fulfilling the requirements listed in their docstrings:\n",
    "* `serialize_model`\n",
    "* `load_model` \n",
    "* `load_prediction_data`\n",
    "\n",
    "Submit a completed version of this notebook, in `.ipynb` format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-01 06:44:35--  https://storage.googleapis.com/security-analytics-datasets-public/PhishStorm-phishing-urls.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.69.240, 142.250.72.16, 142.250.72.48, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.69.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3259236 (3.1M) [application/zip]\n",
      "Saving to: ‘PhishStorm-phishing-urls.zip’\n",
      "\n",
      "PhishStorm-phishing 100%[===================>]   3.11M  1.63MB/s    in 1.9s    \n",
      "\n",
      "2022-03-01 06:44:37 (1.63 MB/s) - ‘PhishStorm-phishing-urls.zip’ saved [3259236/3259236]\n",
      "\n",
      "Archive:  PhishStorm-phishing-urls.zip\n",
      "  inflating: PhishStorm-phishing-urls.csv  \n"
     ]
    }
   ],
   "source": [
    "def load_phish_storm():\n",
    "    if Path('./PhishStorm-phishing-urls.zip').is_file():\n",
    "        print(f'PhishStorm-phishing-urls.zip already exists in local')\n",
    "    else:\n",
    "        !wget https://storage.googleapis.com/security-analytics-datasets-public/PhishStorm-phishing-urls.zip\n",
    "    \n",
    "    if Path('./PhishStorm-phishing-urls.csv').is_file():\n",
    "        print(f'PhishStorm-phishing-urls.csv already exists in local')\n",
    "    else:\n",
    "        !unzip PhishStorm-phishing-urls.zip\n",
    "\n",
    "    df = pd.read_csv(\"PhishStorm-phishing-urls.csv\", encoding_errors='ignore', on_bad_lines='skip', low_memory=False)\n",
    "    return df\n",
    "\n",
    "df = load_phish_storm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peek at the dataframe...\n",
    "\n",
    "This is provided to show you what the data should look like once you have loaded it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>domain</th>\n",
       "      <td>96002</td>\n",
       "      <td>96000</td>\n",
       "      <td>'www.allegropl.xaa.pl/enter_login.html?session...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranking</th>\n",
       "      <td>95951</td>\n",
       "      <td>7016</td>\n",
       "      <td>10000000</td>\n",
       "      <td>56065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mld_res</th>\n",
       "      <td>95935</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mld.ps_res</th>\n",
       "      <td>95924</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_rem</th>\n",
       "      <td>95923.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_Rrem</th>\n",
       "      <td>95923.0</td>\n",
       "      <td>10042.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5632.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_Arem</th>\n",
       "      <td>95923.0</td>\n",
       "      <td>10231.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccard_RR</th>\n",
       "      <td>95922.0</td>\n",
       "      <td>5446.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76866.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccard_RA</th>\n",
       "      <td>95921.0</td>\n",
       "      <td>5628.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccard_AR</th>\n",
       "      <td>95920.0</td>\n",
       "      <td>5071.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77689.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccard_AA</th>\n",
       "      <td>95919.0</td>\n",
       "      <td>5313.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76856.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccard_ARrd</th>\n",
       "      <td>95919</td>\n",
       "      <td>708</td>\n",
       "      <td>0</td>\n",
       "      <td>53064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccard_ARrem</th>\n",
       "      <td>95917</td>\n",
       "      <td>26085</td>\n",
       "      <td>0</td>\n",
       "      <td>5769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>95913.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48009.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count   unique  \\\n",
       "domain           96002    96000   \n",
       "ranking          95951     7016   \n",
       "mld_res          95935       19   \n",
       "mld.ps_res       95924        8   \n",
       "card_rem       95923.0     53.0   \n",
       "ratio_Rrem     95923.0  10042.0   \n",
       "ratio_Arem     95923.0  10231.0   \n",
       "jaccard_RR     95922.0   5446.0   \n",
       "jaccard_RA     95921.0   5628.0   \n",
       "jaccard_AR     95920.0   5071.0   \n",
       "jaccard_AA     95919.0   5313.0   \n",
       "jaccard_ARrd     95919      708   \n",
       "jaccard_ARrem    95917    26085   \n",
       "label          95913.0      2.0   \n",
       "\n",
       "                                                             top     freq  \n",
       "domain         'www.allegropl.xaa.pl/enter_login.html?session...        2  \n",
       "ranking                                                 10000000    56065  \n",
       "mld_res                                                      0.0    52217  \n",
       "mld.ps_res                                                   0.0    76496  \n",
       "card_rem                                                     2.0  17179.0  \n",
       "ratio_Rrem                                                   0.0   5632.0  \n",
       "ratio_Arem                                                   0.0   5686.0  \n",
       "jaccard_RR                                                   0.0  76866.0  \n",
       "jaccard_RA                                                   0.0  75286.0  \n",
       "jaccard_AR                                                   0.0  77689.0  \n",
       "jaccard_AA                                                   0.0  76856.0  \n",
       "jaccard_ARrd                                                   0    53064  \n",
       "jaccard_ARrem                                                  0     5769  \n",
       "label                                                        0.0  48009.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/48997644/how-to-describe-columns-as-categorical-values\n",
    "df.astype('object').describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model and save it to disk\n",
    "\n",
    "In this section, we first simulate the machine learning process of\n",
    "data preparation, model fitting, and model evaluation. \n",
    "\n",
    "At the end of this section, we serialize (save) our fitted model to disk using \n",
    "python's `pickle` library.\n",
    "\n",
    "### Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineer\n",
    "\n",
    "We create a feature calculated from the length of the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['domain_len'] = df['domain'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition the data\n",
    "\n",
    "We select our new column to be the sole predictor, and we calculate a test-train split.\n",
    "We fit a Logistic Regression model using model defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['domain_len']]\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save some data to disk, to use later in the deployment phase\n",
    "\n",
    "We now save some testing data to disk in JSON format.\n",
    "Later, we will load it back, and ask our unserialized model\n",
    "to get predictions for it. This will simulate our serialized model\n",
    "having been deployed somewhere, and having been asked to make\n",
    "predictions against data sent in json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.sample(n=5).to_json('test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.752801960068811"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a bad performance considering we only used one predictor..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model to disk\n",
    "\n",
    "In this step, we save our fitted model to disk via serializing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize your fitted sklearn classifier (`clf`) to disk.\n",
    "# hint: https://docs.python.org/3/library/pickle.html#examples\n",
    "def serialize_model(clf):\n",
    "    with open('df.pickle', 'wb') as f:\n",
    "        pickle.dump(clf, f, pickle.HIGHEST_PROTOCOL) # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        \n",
    "serialize_model(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the deployed the model\n",
    "\n",
    "Imagine that the code in the following section is running in a separate context \n",
    "from all code that ran before it. \n",
    "\n",
    "**Important!** When I run your code, I should be able\n",
    "to successfully run each of the cells below *even if none of the previous cells have been run within the current kernel*,\n",
    "(assuming the pickled model file and json data exist on disk).\n",
    "\n",
    "You can test your code the way I will by doing the following:\n",
    "\n",
    "1. first running all cells so that the files are written to disk\n",
    "1. then running \"Restart Kernel\" from the jupyter \"Kernel\" menu,\n",
    "1. and then by manually running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "#load your fitted sklearn classifier from disk. returns: sklearn classifier\n",
    "#hint: https://docs.python.org/3/library/pickle.html#examples\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    with open('df.pickle', 'rb') as f:\n",
    "        clf_loaded = pickle.load(f)\n",
    "    return clf_loaded\n",
    "\n",
    "clf_loaded = load_model()\n",
    "\n",
    "# load your json data into a pandas data frame. Earlier, we saved it to disk as filename `test.json`\n",
    "# hint: https://pandas.pydata.org/docs/reference/api/pandas.read_json.html. returns: pandas df\n",
    "\n",
    "def load_prediction_data():\n",
    "    test_data_sample = pd.read_json(\"test.json\")\n",
    "    return test_data_sample\n",
    "\n",
    "# Load the prediction data\n",
    "test_data_sample = load_prediction_data()\n",
    "\n",
    "# Get predictions for the uploaded data\n",
    "clf_loaded.predict(test_data_sample)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab -- Publicly Accessible Datasets | submission template",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
